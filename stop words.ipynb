{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP WORDS FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING LIBRARIES\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMPLE TEXT\n",
    "text = \"I have a meeting scheduled at tommorrow morning at 7:30 sharp.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOKENIZING WORDS\n",
    "words = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING LIST OF STOPWORDS IN ENGLISH \n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['I', 'meeting', 'scheduled', 'tommorrow', 'morning', '7:30', 'sharp', '.']\n"
    }
   ],
   "source": [
    "l = [w for w in words if w not in stop_words]\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REMOVING PUNCTUATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW EXAMPLE \n",
    "sample_text1 = \"The boy was happyâ€¦ at the start of his summer holiday.\"\n",
    "sample_text2 = \"We set out at dawn; the weather looked promising.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVING PUNCTUATIONS \n",
    "tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "new_words1 = tokenizer.tokenize(sample_text1)\n",
    "new_words2 = tokenizer.tokenize(sample_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['The', 'boy', 'was', 'happy', 'at', 'the', 'start', 'of', 'his', 'summer', 'holiday'] \n ['We', 'set', 'out', 'at', 'dawn', 'the', 'weather', 'looked', 'promising']\n"
    }
   ],
   "source": [
    "print(new_words1,\"\\n\",new_words2)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36464bit045738b45aaa495e91227eedbb7f3e8f",
   "display_name": "Python 3.6.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}