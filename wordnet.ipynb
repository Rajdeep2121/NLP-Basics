{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORDNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING LIBRARIES\n",
    "import nltk\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = wordnet.synsets(\"bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "that which is below standard or expectations as of ethics or decency\n"
    }
   ],
   "source": [
    "# DEFINITION OF THE WORD\n",
    "print(word[0].definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['take the bad with the good']\n"
    }
   ],
   "source": [
    "# EXAMPLES IN SENTENCES\n",
    "print(word[0].examples())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYNONYMS AND ANTONYMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Synonyms: ['sorry', 'bad', 'uncollectible', 'badness', 'defective', 'spoiled', 'speculative', 'spoilt', 'high-risk', 'forged', 'badly', 'risky', 'unfit', 'regretful', 'tough', 'unsound', 'big']\nAntonyms: ['goodness', 'unregretful', 'good']\n"
    }
   ],
   "source": [
    "antonyms = []\n",
    "synonyms = []\n",
    "for i in word:\n",
    "    for l in i.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if(l.antonyms()):\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "\n",
    "\n",
    "# REMOVING DUPLICATES\n",
    "print(\"Synonyms:\",list(set(synonyms)))\n",
    "print(\"Antonyms:\",list(set(antonyms)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMILARITY MEASURE BETWEEN TWO WORDS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.9090909090909091\n"
    }
   ],
   "source": [
    "w1 = wordnet.synset(\"ship.n.01\")\n",
    "w2 = wordnet.synset(\"boat.n.01\")\n",
    "\n",
    "print(w1.wup_similarity(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.08695652173913043\n"
    }
   ],
   "source": [
    "w1 = wordnet.synset(\"ship.n.01\")\n",
    "w2 = wordnet.synset(\"cruise.n.01\")\n",
    "\n",
    "print(w1.wup_similarity(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.3333333333333333\n"
    }
   ],
   "source": [
    "w1 = wordnet.synset(\"ship.n.01\")\n",
    "w2 = wordnet.synset(\"mouse.n.01\")\n",
    "\n",
    "print(w1.wup_similarity(w2))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36464bit045738b45aaa495e91227eedbb7f3e8f",
   "display_name": "Python 3.6.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}